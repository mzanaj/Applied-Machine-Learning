{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snEnoaKIHAo7"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Homework 7: Deep Learning\n",
    "\n",
    "For this assignment, question 1 is worth 50 points, and question 2 is worth 40 points, for a total of 90 points. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "Submit your completed notebook file AND corresponding **HTML** file to the Canvas site.\n",
    "\n",
    "As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates: if you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuzKPRVbIZa4"
   },
   "source": [
    "### Put your name here: Martin Zanaj\n",
    "\n",
    "### Put your uniquename here: mzanaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MoM5xcOIbQ4"
   },
   "source": [
    "### Question 1 Comparing ML with DL (50 points)\n",
    "\n",
    "In this question, we are still exploring classifying the IMDB movie data set as we did in the lab.   You will use the different classifiers you learned in this course: (1) LinearSVC; (2) RandomForestClassifier; (3) Deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJXpYJ7OJaGc"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VOcDl-HaA7v_"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtbYQ4ePG9G5"
   },
   "source": [
    "### Question 1(a) (10 points)\n",
    "Please use LinearSVC to train the model and return the mean accuracy on the given test data and labels. You can use the default parameteers in LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTNinbb2Y4co",
    "outputId": "de26634d-d45e-43b7-ba9d-24c7577bddfe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8356"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one_a():\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    #Pipeline\n",
    "    clf = Pipeline([('scalar',MinMaxScaler()),('LinerSVC',LinearSVC())])\n",
    "    \n",
    "    #Fit\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    #Prediction\n",
    "    svc_preidction= clf.predict(x_test)\n",
    "\n",
    "    #Accuracy Score\n",
    "    test_score= accuracy_score(svc_preidction,y_test)\n",
    "\n",
    "    #Score (same as accuracy)\n",
    "    test_score = clf.score(x_test, y_test)\n",
    "    \n",
    "    return test_score\n",
    "\n",
    "answer_one_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImowCOgQK3tb"
   },
   "source": [
    "### Question 1(b) (10 points)\n",
    "Please use RandomForestClassifier (with random_state = 0) to train the model and return the mean accuracy on the given test data and labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "haEhg85RGSS1",
    "outputId": "362148e4-b8e4-4ba0-91e4-3e7b8a80f575"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84384"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one_b():\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    #Random Forest\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "    #Fit\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    #Test score\n",
    "    test_score = clf.score(x_test, y_test)\n",
    "  \n",
    "    return test_score\n",
    "answer_one_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ydNcuKDMLA3"
   },
   "source": [
    "### Question 1(c) (20 points)\n",
    "\n",
    "Please use the below architecture of the dense layers to design your model:\n",
    "one intermediate layers with 32 hidden units, \n",
    "and a second layer which will output the scalar prediction regarding the sentiment of the current review. \n",
    "\n",
    "The intermediate layer will use `relu` as its \"activation function\", \n",
    "and the final layer will use a sigmoid activation so as to output a probability \n",
    "(a score between 0 and 1, indicating how likely the sample is to have the target \"1\", i.e. how likely the review is to be positive). \n",
    "A `relu` (rectified linear unit) is a function meant to zero-out negative values, \n",
    "while a sigmoid \"squashes\" arbitrary values into the `[0, 1]` interval, thus outputting something that can be interpreted as a probability.\n",
    "\n",
    "We configure our model with the `rmsprop` optimizer and the `binary_crossentropy` loss function as we did in the lab. Note that we will \n",
    "also monitor accuracy during training.\n",
    "\n",
    "For model fitting, we train our model for 4 epochs (4 iterations over all samples in the x_train and y_train tensors), in mini-batches of 512 samples.\n",
    "\n",
    "Please return the testing accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nEJEwy6MlXq",
    "outputId": "cf2678df-faef-47c3-8192-665fb72f9ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.4101 - accuracy: 0.8314\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.2445 - accuracy: 0.9134\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.1959 - accuracy: 0.9305\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.1670 - accuracy: 0.9416\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.2940 - accuracy: 0.8827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29404348134994507, 0.8826799988746643]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one_c():\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "\n",
    "    #write your code here\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "    results = model.evaluate(x_test, y_test)\n",
    "    return results\n",
    "\n",
    "answer_one_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zq81A_NPRVd"
   },
   "source": [
    "### Question 1(d) Open Question (10 points)\n",
    "**Can you conclude that deep learning is better than the classic ML models on this task?**\n",
    "\n",
    "\n",
    "As they get better on their training data, neural networks eventually start overfitting and end up obtaining increasingly worse results on data never-seen-before. Hence, it makes sense to check if we are indeed overfitting (or underfitting). \n",
    "\n",
    "I have run the model on a validation set (results below), so as to check for overfitting. It is apparent form the training & validation train/test scores that around epoch 3 & 4 (best test score) there is no overfitting. This represents that our model is not overfitting, nor underfitting.  In comparison to the other models, we are indeed getting a better accuracy scores. Also, we could make additional adjustments to out model architecture that could indeed better the oveall performance. Hence, I would conclude that **Deep Learning is better** on the basis that the accuracy is higher & that there is no apparent overfitting.  \n",
    "\n",
    "**If so, what do you think that helps Deep Learning perform better?**\n",
    "\n",
    "* Deep learning networks can learn very complicated relationships. They can form a much deeper understanding of a sequence and its context, compared to other algorithms  (random forest/linearSVC).\n",
    "\n",
    "* Perhaps, in this setting the features are learned my the machine, rather than forced by the intuition of the desginer (me). Hence, this lack  of imposition allows for the true structures to emerge. \n",
    "\n",
    "* Stacks of `Dense` layers with `relu` activations can solve a wide range of problems which allows to capture relationships that can be missed by other models techniques. \n",
    "\n",
    "* Can use different network structures to improve performance & add featuers such as embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Hv14YdnyBuF",
    "outputId": "e88fc171-05a2-4923-c2d0-cb3fc6655c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.4857 - accuracy: 0.7916 - val_loss: 0.3656 - val_accuracy: 0.8670\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.2919 - accuracy: 0.9043 - val_loss: 0.3042 - val_accuracy: 0.8869\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.2218 - accuracy: 0.9301 - val_loss: 0.2784 - val_accuracy: 0.8916\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.1810 - accuracy: 0.9427 - val_loss: 0.2731 - val_accuracy: 0.8907\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.1513 - accuracy: 0.9529 - val_loss: 0.2767 - val_accuracy: 0.8881\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.1249 - accuracy: 0.9641 - val_loss: 0.2839 - val_accuracy: 0.8861\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.1105 - accuracy: 0.9683 - val_loss: 0.3109 - val_accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.0922 - accuracy: 0.9759 - val_loss: 0.3076 - val_accuracy: 0.8832\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0820 - accuracy: 0.9788 - val_loss: 0.3235 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.0693 - accuracy: 0.9835 - val_loss: 0.3373 - val_accuracy: 0.8817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "#write your code here\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "Ixm_TIXxyxbJ",
    "outputId": "c7bc3537-9e46-4423-dae8-315e0786eee5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.3656480610370636,\n",
       " 0.30420365929603577,\n",
       " 0.27836844325065613,\n",
       " 0.2730787396430969,\n",
       " 0.2766709327697754,\n",
       " 0.2838616669178009,\n",
       " 0.31086641550064087,\n",
       " 0.30760645866394043,\n",
       " 0.3235381245613098,\n",
       " 0.3373151123523712]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "gMWrbt2izJY6",
    "outputId": "307abeb9-a97c-4687-9bce-e06e18647df0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 11)\n",
      "[0.8669999837875366, 0.886900007724762, 0.8916000127792358, 0.8906999826431274, 0.8881000280380249, 0.8860999941825867, 0.8794000148773193, 0.8831999897956848, 0.881600022315979, 0.8816999793052673]\n"
     ]
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "print(epochs)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3PSt7I5R6fC"
   },
   "source": [
    "## Question 2 Hyper-parameteer tunning in DL (40 points)\n",
    "\n",
    "We have shown you how to tune parameters such as training epoch in the lab. \n",
    "\n",
    "In this question, we are exploring the hyper-parameteer tuning in deep learning from the perspective of the size of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPfJlhYKTnMo"
   },
   "source": [
    "First, we divide some part of training data into valiadation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fd3GmUL4TmKO"
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOGtwWvATxKi"
   },
   "source": [
    "### Question 2(a): (30 points)\n",
    "\n",
    "Follow the IMDB classification question in Question 1, we hope you design and test different neural network. You shall vary the first intermediate layer with [3, 6, 9, 12] hidden units, and the second intermediate layer with [2, 4, 6, 8] hidden units. \n",
    "\n",
    "The last layer which will output the scalar prediction regarding the sentiment of the current review. \n",
    "\n",
    "Apply the different models onto the valiadation set and return the best model with highest accuracy on the valiadation. You should three numbers, which represent the best model's number of hideen units in first, second intermediate layer, and the best accuracy. \n",
    "\n",
    "Fit the model by using the default setting in 1(c). (epochs = 4, batch_sze = 512, optimizer = rmsprop, loss = binary_crossentropy, metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybSD6iByUz3n",
    "outputId": "201cead3-26cb-4525-94e3-9690a76ebaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6428 - accuracy: 0.6575\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5675 - accuracy: 0.7660\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5216 - accuracy: 0.8194\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4872 - accuracy: 0.8557\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.8172\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6495 - accuracy: 0.6121\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5777 - accuracy: 0.7394\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5326 - accuracy: 0.8027\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4976 - accuracy: 0.8413\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.8071\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.6007 - accuracy: 0.7437\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4579 - accuracy: 0.8701\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.3672 - accuracy: 0.8959\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.3030 - accuracy: 0.9115\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8821\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6406 - accuracy: 0.6418\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5571 - accuracy: 0.7979\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4973 - accuracy: 0.8545\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4486 - accuracy: 0.8908\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4680 - accuracy: 0.8370\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5659 - accuracy: 0.7650\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.3868 - accuracy: 0.8933\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.2937 - accuracy: 0.9201\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.2343 - accuracy: 0.9339\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.8843\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6007 - accuracy: 0.7105\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5094 - accuracy: 0.8295\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.4659 - accuracy: 0.8691\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4343 - accuracy: 0.8967\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4728 - accuracy: 0.8671\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6064 - accuracy: 0.6746\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4442 - accuracy: 0.8715\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.3286 - accuracy: 0.9093\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.2595 - accuracy: 0.9265\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8881\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5554 - accuracy: 0.7666\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.3752 - accuracy: 0.8901\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.2823 - accuracy: 0.9162\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.2262 - accuracy: 0.9312\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.8903\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5323 - accuracy: 0.7659\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3441 - accuracy: 0.8990\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2633 - accuracy: 0.9215\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2130 - accuracy: 0.9365\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.8903\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5115 - accuracy: 0.7875\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3251 - accuracy: 0.9025\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2477 - accuracy: 0.9243\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2025 - accuracy: 0.9387\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2884 - accuracy: 0.8861\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.5549 - accuracy: 0.7711\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3743 - accuracy: 0.8921\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2819 - accuracy: 0.9173\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2253 - accuracy: 0.9327\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2854 - accuracy: 0.8909\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.5532 - accuracy: 0.7674\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3591 - accuracy: 0.8912\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2674 - accuracy: 0.9167\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2126 - accuracy: 0.9347\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.8915\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5971 - accuracy: 0.6103\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4941 - accuracy: 0.8045\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4498 - accuracy: 0.8709\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4185 - accuracy: 0.9059\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.8437\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.5865 - accuracy: 0.7281\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.4281 - accuracy: 0.8785\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.3247 - accuracy: 0.9161\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.2543 - accuracy: 0.9305\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3035 - accuracy: 0.8911\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5313 - accuracy: 0.7763\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3337 - accuracy: 0.8985\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2479 - accuracy: 0.9242\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.1982 - accuracy: 0.9373\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8902\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.5635 - accuracy: 0.7888\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3510 - accuracy: 0.8923\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2609 - accuracy: 0.9191\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2074 - accuracy: 0.9339\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.8902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 8, 0.8914999961853027)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two_a():\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "\n",
    "    best_first, best_second, best_res = 0, 0, 0\n",
    "    for first_layer in [3, 6, 9, 12]:\n",
    "        for second_layer in [2, 4, 6, 8]:\n",
    "          #Initialize sequential model \n",
    "          model = models.Sequential()\n",
    "\n",
    "          #Layer 1\n",
    "          model.add(layers.Dense(first_layer, activation='relu', input_shape=(10000,)))\n",
    "\n",
    "          #Layer 2 \n",
    "          model.add(layers.Dense(second_layer, activation='relu', input_shape=(10000,)))\n",
    "            \n",
    "          #Prediction Layer\n",
    "          model.add(layers.Dense(1, activation='sigmoid'))\n",
    " \n",
    "          #Compile Mode\n",
    "          model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "          #Fit\n",
    "          model.fit(partial_x_train, partial_y_train, epochs=4, batch_size=512)\n",
    "\n",
    "          # Testing error\n",
    "          results = model.evaluate(x_val, y_val)\n",
    "          \n",
    "          if(results[1]>best_res):\n",
    "            best_first, best_second, best_res =first_layer,second_layer,results[1]\n",
    "      \n",
    "    return best_first, best_second, best_res\n",
    "\n",
    "answer_two_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em0olr1NX9jQ"
   },
   "source": [
    "### Question 2(b): (10 points)\n",
    "\n",
    "**According to the performance we observed for the models. Which design is best for this task?**\n",
    "\n",
    "After taking in account the different models performances, it looks that the best model is the Deep learning model with two layers; where the **first layer is 9 & the second layer is 8** . I re-ran the model on the entire dataset. The accuracy score  on the test data is indeed better (slightly) even than the models in question 1. \n",
    "\n",
    "**What take-away do you get from this question? Does it mean larger network improve the model's performance?**\n",
    "\n",
    "More flexibility does not necessarily mean that we will get a better accuracy on the testing data. Instead the **right degree of flexibility**(largness) is crucial so as to make use of the power of deep learning and at the same time ensure that that we are  putting restrictions to avoid over-fitting. \n",
    "\n",
    "For example, below is the list of accuracy values from a previous modeling attempt. It is noticable that when the network is with configuration 3,2 (first) the accuracy is 0.88; on the other hand, when the network is with configuration 12,6 (one-to last), the accuracy is almost is 0.87. Hence, a larger network does not necessarily mean a better accuracy. \n",
    "\n",
    "[[3, 2, 0.8824999928474426],\n",
    "\n",
    "  [3, 4, 0.8672999739646912],\n",
    "\n",
    "  [3, 6, 0.8754000067710876],\n",
    "\n",
    "  [3, 8, 0.880299985408783],\n",
    "\n",
    "  [6, 2, 0.8421000242233276],\n",
    "\n",
    "  [6, 4, 0.8616999983787537],\n",
    "\n",
    "  [6, 6, 0.8865000009536743],\n",
    "\n",
    "  [6, 8, 0.8906999826431274],\n",
    "\n",
    "  [9, 2, 0.8888000249862671],\n",
    "\n",
    "  [9, 4, 0.8871999979019165],\n",
    "\n",
    "  [9, 6, 0.8881000280380249],\n",
    "\n",
    "  [9, 8, 0.8878999948501587],\n",
    "\n",
    "  [12, 2, 0.8889999985694885],\n",
    "\n",
    "  [12, 4, 0.8924000263214111],\n",
    "\n",
    "  [12, 6, 0.8740000128746033],\n",
    "\n",
    "  [12, 8, 0.8880000114440918]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZxlvOWgYKS5",
    "outputId": "8142c4d0-f24a-404a-8c39-b48f0cf4cd83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.5156 - accuracy: 0.7934\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.3154 - accuracy: 0.9048\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.2336 - accuracy: 0.9211\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.1913 - accuracy: 0.9348\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.2873 - accuracy: 0.8856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2872650921344757, 0.8855999708175659]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "#Initialize sequential model \n",
    "model = models.Sequential()\n",
    "\n",
    "#Layer 1\n",
    "model.add(layers.Dense(9, activation='relu', input_shape=(10000,)))\n",
    "\n",
    "#Layer 2 \n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(10000,)))\n",
    "            \n",
    "#Prediction Layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compile Mode\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Fit\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "# Testing error\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Puq_fu7-bdrh",
    "outputId": "18ea8c2a-fe63-454b-b1d4-3b15eaec0b70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.6152 - accuracy: 0.7161\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5108 - accuracy: 0.8439\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4464 - accuracy: 0.8893\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.3871 - accuracy: 0.9170\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4043 - accuracy: 0.8825\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6134 - accuracy: 0.6562\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5210 - accuracy: 0.8014\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4740 - accuracy: 0.8605\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4408 - accuracy: 0.8956\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4737 - accuracy: 0.8673\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.6315 - accuracy: 0.7326\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4993 - accuracy: 0.8631\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4058 - accuracy: 0.8853\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.3232 - accuracy: 0.8999\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8754\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.6046 - accuracy: 0.7648\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4574 - accuracy: 0.8733\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.3579 - accuracy: 0.8991\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2910 - accuracy: 0.9149\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8803\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5918 - accuracy: 0.7183\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.4904 - accuracy: 0.8448\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4474 - accuracy: 0.8835\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4186 - accuracy: 0.9089\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.8421\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.6342 - accuracy: 0.6675\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5498 - accuracy: 0.7883\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5017 - accuracy: 0.8425\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.4659 - accuracy: 0.8760\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.8617\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5330 - accuracy: 0.7819\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.3431 - accuracy: 0.9011\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2610 - accuracy: 0.9249\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2128 - accuracy: 0.9373\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2920 - accuracy: 0.8865\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.5635 - accuracy: 0.7751\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.3882 - accuracy: 0.8923\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.2981 - accuracy: 0.9165\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2411 - accuracy: 0.9301\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.8907\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.5713 - accuracy: 0.7643\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4098 - accuracy: 0.8900\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3166 - accuracy: 0.9135\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2564 - accuracy: 0.9279\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8888\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.6293 - accuracy: 0.7221\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4987 - accuracy: 0.8676\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3990 - accuracy: 0.8964\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3237 - accuracy: 0.9132\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8872\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5216 - accuracy: 0.7935\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3322 - accuracy: 0.9005\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2547 - accuracy: 0.9204\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2080 - accuracy: 0.9351\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.8881\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5470 - accuracy: 0.7849\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3330 - accuracy: 0.9022\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2445 - accuracy: 0.9283\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1951 - accuracy: 0.9411\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2807 - accuracy: 0.8879\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5350 - accuracy: 0.7827\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3516 - accuracy: 0.8967\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2687 - accuracy: 0.9176\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2176 - accuracy: 0.9337\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.8890\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5777 - accuracy: 0.7664\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4039 - accuracy: 0.8887\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3088 - accuracy: 0.9142\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2483 - accuracy: 0.9278\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2970 - accuracy: 0.8924\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6174 - accuracy: 0.6635\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.5144 - accuracy: 0.8238\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.4381 - accuracy: 0.8841\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3557 - accuracy: 0.9221\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3766 - accuracy: 0.8740\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5561 - accuracy: 0.7712\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3526 - accuracy: 0.8953\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2593 - accuracy: 0.9189\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2047 - accuracy: 0.9366\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2801 - accuracy: 0.8880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " 4,\n",
       " 0.8924000263214111,\n",
       " [[3, 2, 0.8824999928474426],\n",
       "  [3, 4, 0.8672999739646912],\n",
       "  [3, 6, 0.8754000067710876],\n",
       "  [3, 8, 0.880299985408783],\n",
       "  [6, 2, 0.8421000242233276],\n",
       "  [6, 4, 0.8616999983787537],\n",
       "  [6, 6, 0.8865000009536743],\n",
       "  [6, 8, 0.8906999826431274],\n",
       "  [9, 2, 0.8888000249862671],\n",
       "  [9, 4, 0.8871999979019165],\n",
       "  [9, 6, 0.8881000280380249],\n",
       "  [9, 8, 0.8878999948501587],\n",
       "  [12, 2, 0.8889999985694885],\n",
       "  [12, 4, 0.8924000263214111],\n",
       "  [12, 6, 0.8740000128746033],\n",
       "  [12, 8, 0.8880000114440918]])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two_a():\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "\n",
    "    best_first, best_second, best_res = 0, 0, 0\n",
    "    thy=[]\n",
    "    for first_layer in [3, 6, 9, 12]:\n",
    "        for second_layer in [2, 4, 6, 8]:\n",
    "          #Initialize sequential model \n",
    "          model = models.Sequential()\n",
    "\n",
    "          #Layer 1\n",
    "          model.add(layers.Dense(first_layer, activation='relu', input_shape=(10000,)))\n",
    "\n",
    "          #Layer 2 \n",
    "          model.add(layers.Dense(second_layer, activation='relu', input_shape=(10000,)))\n",
    "            \n",
    "          #Prediction Layer\n",
    "          model.add(layers.Dense(1, activation='sigmoid'))\n",
    " \n",
    "          #Compile Mode\n",
    "          model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "          #Fit\n",
    "          model.fit(partial_x_train, partial_y_train, epochs=4, batch_size=512)\n",
    "\n",
    "          # Testing error\n",
    "          results = model.evaluate(x_val, y_val)\n",
    "          a=[first_layer,second_layer, results[1]]\n",
    "          thy.append(a)\n",
    "          if(results[1]>best_res):\n",
    "            best_first, best_second, best_res =first_layer,second_layer,results[1]\n",
    "      \n",
    "    return best_first, best_second, best_res, thy\n",
    "\n",
    "answer_two_a()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PuzKPRVbIZa4",
    "-MoM5xcOIbQ4"
   ],
   "name": "si670f20_hw_7_mzanaj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
