{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWTe9VS3_b11"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Week 3:  Regularization, Logistic Regression, and Evaluation (Due 09/28 11:59pm)\n",
    "\n",
    "For this assignment, you will be exercising on questions related to linear regression, polynomial feature expansion, underfitting/overfitting, and cross-validation.\n",
    "\n",
    "Each question is worth 20 points, for a total of 100 points. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "Submit your completed notebook file to the Canvas site - IMPORTANT: please name your submitted file si670-hw1-youruniqname.ipynb and be sure to put your name at the top of your notebook file. Please also make sure to upload the html version.\n",
    "\n",
    "As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates: if you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put your name here: Martin Zanaj\n",
    "\n",
    "### Put your uniquename here: mzanaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_pUE4abw2eQ"
   },
   "source": [
    "### Preliminary\n",
    "In this assignment you will train several linear classifier models and evaluate how effectively they predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud). Then you'll perform a grid search to find optimal parameters. \n",
    " \n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are using Jupyter\n",
    "files = {'fraud_data.csv': 'fraud_data.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(files['fraud_data.csv'])\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will avoid displaying warning messages against logistic's regression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itE2L8t4w2ee"
   },
   "source": [
    "### Question 1 (20 points)\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
    "\n",
    "Then train a LogisticRegression classifier with C=1. What is the accuracy? What is the recall?\n",
    "\n",
    "*This function should a return a tuple with four floats, i.e. `(dummy_accuracy, dummy_recall, lr_accuracy, lr_recall)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9983146540827504, 0.0, 0.9990871042948232, 0.6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score,recall_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    #Dummy classifier\n",
    "    #Negative class (0) is most frequent, frauds are less likely to happen\n",
    "    dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "    y_majority_predicted = dummy_majority.predict(X_test)\n",
    "    \n",
    "    #Logistics Classifier\n",
    "    lr = LogisticRegression(C=1).fit(X_train, y_train)\n",
    "    lr_predicted = lr.predict(X_test)\n",
    "        \n",
    "    #Metrics\n",
    "    dummy_accuracy= accuracy_score(y_test, y_majority_predicted)\n",
    "    dummy_recall = recall_score(y_test, y_majority_predicted)\n",
    "    \n",
    "    lr_accuracy= accuracy_score(y_test, lr_predicted)\n",
    "    lr_recall = recall_score(y_test, lr_predicted)\n",
    "    \n",
    "    \n",
    "    #Double check metrics\n",
    "    #Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "    #Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "    confusion_d = confusion_matrix(y_test, y_majority_predicted)\n",
    "    confusion_l = confusion_matrix(y_test, lr_predicted)\n",
    "    \n",
    "    return dummy_accuracy, dummy_recall, lr_accuracy, lr_recall\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (20 points)\n",
    "\n",
    "Fit the LogisticRegression with `C` varying from `[[0.1, 1, 10]` and report the accuracy, precision, recall, and F1 scores for each choice of `C`.\n",
    "\n",
    "*This function should a return a tuple with four lists, i.e. `(accuracy_list, precision_list, recall_list, f1_list)`, and each list should contain 3 numbers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9990871042948232, 0.9990871042948232, 0.9990871042948232],\n",
       " [0.8089887640449438, 0.8089887640449438, 0.8089887640449438],\n",
       " [0.6, 0.6, 0.6],\n",
       " [0.6889952153110048, 0.6889952153110048, 0.6889952153110048])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    #Logistics regression for different  C levels\n",
    "    C= [0.1,1,10]\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for c_level in C:\n",
    "        #Model, prediction\n",
    "        logr = LogisticRegression(C=c_level).fit(X_train, y_train)\n",
    "        logr_pred = logr.predict(X_test)\n",
    "        \n",
    "        #Metrics\n",
    "        accuracy_list.append(accuracy_score(y_test, logr_pred))\n",
    "        precision_list.append(precision_score(y_test, logr_pred))\n",
    "        recall_list.append(recall_score(y_test, logr_pred))\n",
    "        f1_list.append(f1_score(y_test, logr_pred))\n",
    "        #print(confusion_matrix(y_test, logr_pred))\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_list\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (20 points)\n",
    "\n",
    "Train a logistic regression classifier with `C=10` using X_train and y_train.\n",
    "\n",
    "For the logistic regression classifier, create (1) a precision-recall curve and (2) a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
    "\n",
    "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
    "\n",
    "Looking at the ROC curve, what is the true positive rate when the false positive rate is `0.16`?\n",
    "\n",
    "*This function should return a tuple with two floats, i.e. `(recall_at_p75, tpr_at_fpr16)`.*\n",
    "*You should also includce code to generate the precision/recall and ROC curves above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.7, 0.75)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    #Model, prediction\n",
    "    logr = LogisticRegression(C=10).fit(X_train, y_train)\n",
    "    logr_pred = logr.predict(X_test)    \n",
    "    y_score = logr.decision_function(X_test)\n",
    "\n",
    "    #Precision Recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    \n",
    "    #Precision Recall graph\n",
    "    plt.figure()\n",
    "    plt.xlim([0.0, 1.01])\n",
    "    plt.ylim([0.0, 1.01])\n",
    "    plt.plot(precision, recall, label='Precision-Recall Curve')\n",
    "    \n",
    "    plt.xlabel('Precision', fontsize=16)\n",
    "    plt.ylabel('Recall', fontsize=16)\n",
    "    plt.title('Precision vs Recall')\n",
    "    plt.axes().set_aspect('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)  \n",
    "    roc_auc = auc(fpr, tpr) \n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.xlim([-0.01, 1.00])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.plot(fpr, tpr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc))\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
    "    plt.legend(loc='lower right', fontsize=13)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "    plt.axes().set_aspect('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    #These are approximations from looking at the graph\n",
    "    recall_at_p75 = 0.70\n",
    "    tpr_at_fpr16 = 0.75\n",
    "    \n",
    "    return recall_at_p75, tpr_at_fpr16\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 Points)\n",
    "\n",
    "Suppose you have trained a classifier distinguishing Benign vs Malignant cancers. And the confusion matrix of your classifier is given below.\n",
    "\n",
    "|      \t| Predicted: Benign \t| Predicted: Malignant \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| Actual: Benign \t|    10000\t|   100 \t|\n",
    "| Actual: Malignant  \t|    200\t|   10 \t|\n",
    "\n",
    "### Question (a) (10 points) \n",
    "If we assume Benign is the positive class and Malignant is the negative class, what are the precision and recall for Benign? If we assume Malignant is the positive class and Benign is the negative class, what are the precision and recall for Malignant?\n",
    "\n",
    "*This function should return a tuple of four float numbers: `(precision_benign, recall_genign, precision_maligant, recall_maligant)`. You can calculate these scores either by coding or by hands.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9803921568627451,\n",
       " 0.9900990099009901,\n",
       " 0.09090909090909091,\n",
       " 0.047619047619047616)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four_a():\n",
    "    \n",
    "    #Benign ==1 , Malign==0\n",
    "    #Precision, TP/ TP+FP\n",
    "    precision_benign = 10000/ (10000+200)\n",
    "    #Recall, TP/TP+FN\n",
    "    recall_genign = 10000/ (10000+100)\n",
    "       \n",
    "    #Malign==1 , Benign ==0\n",
    "    #Precision, TP/ TP+FP\n",
    "    precision_maligant = 10/ (10+ 100)\n",
    "    #Recall, TP/TP+FN\n",
    "    recall_maligant =  10/ (10+200)\n",
    "    \n",
    "    #Fscores\n",
    "    f_score1= 2* (precision_benign*recall_genign)/ (precision_benign+recall_genign)\n",
    "    f_score2= 2* (precision_maligant*recall_maligant)/ (precision_maligant+recall_maligant)\n",
    "    \n",
    "#     print(\"F1: \", f_score1)\n",
    "#     print(\"F2: \", f_score2)\n",
    "    return precision_benign, recall_genign, precision_maligant, recall_maligant\n",
    "\n",
    "answer_four_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (b) (10 points) \n",
    "If you have another classifier with the following confusion matrix, which classifier do you prefer and why? (Hint: calculate the precision and recall scores for this classifier and compare with the previous classifier.)\n",
    "\n",
    "|      \t| Predicted: Benign \t| Predicted: Malignant \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| Actual: Benign \t|    7000\t|   3100 \t|\n",
    "| Actual: Malignant  \t|    30\t|   180 \t|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957325746799431 0.693069306930693 0.9451219512195121 0.9904153354632588\n",
      "F1:  0.8172796263864565\n",
      "F2:  0.967238689547582\n"
     ]
    }
   ],
   "source": [
    "#Benign ==1 , Malign==0\n",
    "#Precision, TP/ TP+FP\n",
    "precision_benign = 7000/ (7000+30)\n",
    "#Recall, TP/TP+FN\n",
    "recall_genign = 7000/ (7000+3100)\n",
    "       \n",
    "#Malign==1 , Benign ==0\n",
    "#Precision, TP/ TP+FP\n",
    "precision_maligant = 3100/ (3100+ 180)\n",
    "#Recall, TP/TP+FN\n",
    "recall_maligant =  3100/ (3100+30)\n",
    "print(precision_benign, recall_genign, precision_maligant, recall_maligant)\n",
    "\n",
    "f_score11= 2* (precision_benign*recall_genign)/ (precision_benign+recall_genign)\n",
    "f_score22= 2* (precision_maligant*recall_maligant)/ (precision_maligant+recall_maligant)\n",
    "   \n",
    "print(\"F1: \", f_score11)\n",
    "print(\"F2: \", f_score22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to quesiton 4 (b)\n",
    "\n",
    ">In the **first model** case 1 has high precision & high recall (.98,.99), but in the second case we have poor precision & poor reacall (0.09, 0.04). In the **second model** case 1 has high precision & low recall (.99,.69), and in the second case we have high precision & high reacall (0.94, 0.99).\n",
    "\n",
    ">At first it might not be apparent which model  is the best, and that is why computing the F1 score can help with the final evaluation. \n",
    "\n",
    "     Fscore model 1\n",
    "        - Case 1: 0.98\n",
    "        - Case 2: 0.06\n",
    "        \n",
    "     Fscore model 2\n",
    "        - Case 1: 0.82\n",
    "        - Case 2: 0.97\n",
    "\n",
    ">In conclusion, I would suggest that *model 2* has a better overall performance given that is has a more balanced ratio between precision & recall(FP, FN). Altough, this is preferedd, one must as well consider the *domain of application* and willing to make tradeoffs between the two competing forces of precision & recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgXuLM17VoZ-"
   },
   "source": [
    "## Question 5 (20 Points)\n",
    "\n",
    "Now, we will compare the performance of Ridge, Lasso and OLS perform on the dataset where the relationship between X and y is non-linear.\n",
    "\n",
    "Let's start by generating some data using the function below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_data(n_samples, n_features, noise=0.0, random_state=670):\n",
    "    assert n_features > 1\n",
    "    rs = np.random.RandomState(random_state)\n",
    "    X = rs.uniform(size=(n_samples, n_features))\n",
    "    y = 3 * np.sin(2*np.pi * X[:, 0]) + 6.7 * X[:, 1] + 10 * np.power(X[:, 2], 3) + noise * rs.normal(size=(n_samples,))\n",
    "    return X, y\n",
    "X, y = generate_data(n_samples = 200, n_features=10, noise=1, random_state=670)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (a) Feature expansion (5 points)\n",
    "First, we are going use sklearn.preprocessing.PolynomialFeatures with `degree = 3`  to expand the feature (Remeber we did that in Lab 2!) \n",
    "\n",
    "*This function should return `X_poly`, which is the new feature set after feature expansion.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 5.68227393e-02, 2.27414107e-02, ...,\n",
       "        2.35360618e-02, 4.68318550e-02, 9.31856257e-02],\n",
       "       [1.00000000e+00, 9.05263188e-01, 9.24187355e-01, ...,\n",
       "        4.14924001e-01, 2.41676170e-01, 1.40766431e-01],\n",
       "       [1.00000000e+00, 6.50709351e-01, 1.28597300e-01, ...,\n",
       "        1.59759055e-02, 2.22254166e-02, 3.09196333e-02],\n",
       "       ...,\n",
       "       [1.00000000e+00, 8.93692785e-01, 4.15921030e-01, ...,\n",
       "        3.76747976e-02, 6.24732846e-02, 1.03594751e-01],\n",
       "       [1.00000000e+00, 3.99743480e-01, 8.59403360e-01, ...,\n",
       "        2.18379718e-03, 1.79022498e-03, 1.46758385e-03],\n",
       "       [1.00000000e+00, 2.03035027e-01, 1.87128496e-01, ...,\n",
       "        1.68814391e-04, 1.09333436e-03, 7.08103150e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def answer_five_expansion():\n",
    "    # Polynomial expansion\n",
    "    poly = PolynomialFeatures(degree= 3)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    return X_poly\n",
    "answer_five_expansion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (b) Split and Standardize (5 points)\n",
    "Then, use the `sklearn.preprocessing.StandardScaler` to normalize the feature `X_poly` and split the training and testing data with `train_size = 0.8` and `random_state = 670`. \n",
    "\n",
    "*This function should return the standardized dataset, `standardized_X_poly_train, standardized_X_poly_test, y_poly_train, y_poly_test`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        ,  1.52443361,  1.13127464, ..., -0.75901895,\n",
       "         -0.67388025, -0.62659948],\n",
       "        [ 0.        , -0.76923476,  0.8787083 , ..., -0.12284315,\n",
       "         -0.57675353, -0.80395527],\n",
       "        [ 0.        ,  0.14637105, -0.39850109, ...,  1.50628647,\n",
       "          0.35722254, -0.44911109],\n",
       "        ...,\n",
       "        [ 0.        ,  1.22898015,  0.08764707, ..., -0.79435078,\n",
       "         -0.76681621, -0.79385361],\n",
       "        [ 0.        , -0.31888116,  1.12614288, ..., -0.81659096,\n",
       "         -0.79633825,  0.11136322],\n",
       "        [ 0.        ,  1.00109535,  1.12274753, ...,  0.07180839,\n",
       "          0.59892653,  0.70377897]]),\n",
       " array([[ 0.        ,  1.04609853, -0.55001307, ..., -0.89255471,\n",
       "         -0.83366274,  0.2283439 ],\n",
       "        [ 0.        , -0.53431493, -0.29429849, ..., -0.8764151 ,\n",
       "         -0.65582463,  0.6597581 ],\n",
       "        [ 0.        , -1.5897467 , -0.81312309, ...,  0.46146557,\n",
       "         -0.35623492, -0.8063101 ],\n",
       "        ...,\n",
       "        [ 0.        , -0.63619274, -1.28096832, ..., -0.62394604,\n",
       "         -0.82046789, -0.92368461],\n",
       "        [ 0.        ,  1.32623237, -0.95827421, ..., -0.83560207,\n",
       "         -0.74318029, -0.78301213],\n",
       "        [ 0.        ,  0.8350441 ,  1.61958847, ..., -0.84657108,\n",
       "         -0.37374732,  2.35371418]]),\n",
       " array([ 5.12336358,  8.57605069,  2.5544901 ,  4.15647006, 12.26110953,\n",
       "        10.40688473,  6.66240352,  7.72590606,  7.07161962, 10.69610078,\n",
       "         3.75241444,  2.24888434,  2.07271021,  3.6487069 ,  1.03860673,\n",
       "         8.79748931,  5.02330562, 11.04842055,  9.76524044, 15.11799623,\n",
       "        10.72914314,  5.61817658,  4.18274094,  9.34235906,  2.53722299,\n",
       "        10.52283479,  2.10623688,  7.26857857,  1.6396896 ,  7.24314005,\n",
       "         2.45729037,  4.43629805,  3.67686919,  4.51853739,  3.19595719,\n",
       "        12.48876284,  7.63737384,  3.2772144 ,  4.62721887,  2.32624443,\n",
       "        10.31395788,  9.09347894,  6.3287308 ,  3.67266516, 10.21166462,\n",
       "         6.57624653,  8.76572158,  4.97354918,  5.13206216,  1.62883607,\n",
       "         5.02903353,  8.70287898, 11.78037631,  8.14428692,  5.57189571,\n",
       "         4.62491257,  9.86856596, 16.93861243,  6.35604226,  4.5282634 ,\n",
       "         1.6344041 ,  7.48367264, -1.27441637,  0.9929828 ,  0.02078917,\n",
       "         2.22747573, 12.22384973,  5.28172166,  3.69706981,  3.15018212,\n",
       "         4.56990322,  3.49267597,  5.88083642,  8.63828075,  2.51133159,\n",
       "         5.48693889,  4.50935288, 16.02560533,  0.49918364,  4.48328927,\n",
       "         0.37357513,  4.10630472,  6.01210203,  6.31524906, 15.62350187,\n",
       "         9.35791898,  8.38561993,  6.23820752, 13.18413833,  7.33472029,\n",
       "         2.45504381,  3.37161669,  4.69900999,  6.59990538,  0.7687367 ,\n",
       "        11.22978534,  3.6784359 ,  4.86505404,  4.30676623,  4.60533012,\n",
       "         8.32960574, 10.61146321,  7.16372814, 13.4855887 ,  3.9590474 ,\n",
       "         8.61183911,  6.13059048,  6.56246523,  4.03028619, 12.1185235 ,\n",
       "         9.68436901,  1.41804213,  5.42286025,  7.77308359, 12.72781908,\n",
       "        10.21225963, 11.31836292,  9.08542261,  4.92575797, 13.99022087,\n",
       "         6.96094364,  1.76403254,  9.15662261,  5.75994846,  8.5360311 ,\n",
       "        -0.65690009,  2.80634628, 10.41658817,  2.71327727,  7.62402869,\n",
       "        13.57911971,  2.10176108,  1.83825811,  1.70181118, 10.40820584,\n",
       "         1.10859273,  3.8003933 ,  8.64718587,  0.41788885, 10.15209273,\n",
       "        10.06742167,  2.3043708 ,  3.94315606,  8.49410583, 15.75878018,\n",
       "        15.69204302,  0.71480129, 12.31748962,  2.34733659,  2.83232077,\n",
       "         6.28481379,  2.776313  ,  4.9470681 ,  5.26700422,  3.94969317,\n",
       "         0.37067002,  7.32669397,  0.2813314 ,  5.98948563,  4.06323616]),\n",
       " array([ 6.34701799, 10.82970574,  3.71060638,  2.20031389,  4.21272951,\n",
       "         7.63423834, 11.94565153,  4.42544416,  6.17217164,  7.02674626,\n",
       "         9.67154279,  2.71432886,  0.9242121 ,  4.33493237, 10.65443155,\n",
       "         0.91856048,  2.99771289,  3.1302912 ,  7.97171053,  4.1884179 ,\n",
       "         9.58638144,  7.50957275,  1.47963414, 13.25398522,  2.13356274,\n",
       "         5.04559416,  8.06403494,  5.96944766,  2.54778455,  1.66411186,\n",
       "         3.36368766,  8.83084928,  6.21216761,  1.29260985,  4.1809068 ,\n",
       "         0.10102604,  8.17038335,  6.95707933,  0.69350568,  5.12548029]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def answer_five_split_standardize():\n",
    "    X_poly = answer_five_expansion()\n",
    "    \n",
    "    #Train/Test Dataset\n",
    "    X_train, X_test, y_poly_train, y_poly_test = train_test_split(X_poly, y, random_state=670, train_size= .80)\n",
    "    \n",
    "    #Standardize/normalize the data (mean=0, sd=1)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    standardized_X_poly_train = scaler.fit_transform(X_train)\n",
    "    standardized_X_poly_test = scaler.fit_transform(X_test)\n",
    "    \n",
    "    return standardized_X_poly_train, standardized_X_poly_test, y_poly_train, y_poly_test\n",
    "answer_five_split_standardize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (c-1) Model comparison (2 points)\n",
    "If we train different linear models, i.e., Linear Regression, Ridge, and Lasso, with the pre-processed training set (standardized_X_poly_train, y_poly_train), which model do you expect to generate the best performance on the testing set and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to Question 5 (c-1)\n",
    "Our predictor space is fairly large, and as a result I aspect linear regression (ols) to overfit the training data given that it might perceive the high **random noise** contamination as something real. As a result of this overfit, it will yield a high performance (smalle RSE). The other two methods, Lasso & Ridge, are still in part OLS, but do have some regularization parameters that can aid against overfitting. Finally, I do aspect Lasso to be the best model on the TESTING data, given that it can act as a model/feature selection as it pushes insignificant coefficients to ZERO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (c-2) Model comparison and model selection (8 points)\n",
    "Next, let's see which model indeed performs better on our dataset. In this function, you will:\n",
    "* Train a Linear Regression model (with default settings), and print the training and testing R-squared scores;\n",
    "* Train a Ridge model for each alpha in the `alpha_list`, select the Ridge model that generates the highest R-squared score on the training set, print both the training and testing R-squared scores of the best-performing Ridge model (i.e., the model with the alpha that generates the highest R-squared score);\n",
    "* Train a Lasso model for each alpha in the `alpha_list`, select the Lasso model that generates the highest R-squared score on the training set, print both the training and testing R-squared scores of the best-performing Lasso model (i.e., the Lasso model with the alpha that generates the highest R-squared score);\n",
    "* Return the the training and testing R-squared scores of the Linear Regression model, the best-performing Ridge model, and the best-performing Lasso model: `linreg_r_2_train, linreg_r_2_test, best_ridgereg_r_2_train, best_ridgereg_r_2_test, best_lassoreg_r_2_train, best_lassoreg_r_2_test)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score of Linear Regression (train): 1.000\n",
      "R-squared score of Linear Regression (test): 0.104\n",
      "R-squared score of Ridge Regression (train): 1.000\n",
      "R-squared score of Ridge Regression (test): 0.156\n",
      "R-squared score of Lasso Regression (train): 0.961\n",
      "R-squared score of Lasso Regression (test): 0.617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 0.10400006881135115,\n",
       " 0.9999539315772671,\n",
       " 0.15590690938809149,\n",
       " 0.9612569688756333,\n",
       " 0.6167402758942504)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "\n",
    "def answer_five_compare():\n",
    "    \n",
    "    standardized_X_poly_train, standardized_X_poly_test, y_poly_train, y_poly_test = answer_five_split_standardize()\n",
    "    \n",
    "    alpha_list = [0.01, 0.1, 1, 2, 3, 5, 10, 50, 100, 200]\n",
    "        \n",
    "    # -------------------- Linear Regression ----------------\n",
    "    linreg= LinearRegression().fit(standardized_X_poly_train,y_poly_train)\n",
    "    linreg_r_2_train = linreg.score(standardized_X_poly_train, y_poly_train)\n",
    "    linreg_r_2_test = linreg.score(standardized_X_poly_test, y_poly_test)\n",
    "    \n",
    "    print('R-squared score of Linear Regression (train): {:.3f}'.format(linreg_r_2_train))    \n",
    "    print('R-squared score of Linear Regression (test): {:.3f}'.format(linreg_r_2_test))      \n",
    "    \n",
    "    \n",
    "    # -------------------- Ridge ---------------------------\n",
    "    r2_train_ridge = []\n",
    "    r2_test_ridge = []\n",
    "    for alpha in alpha_list:\n",
    "        linridge = Ridge(alpha = alpha)\n",
    "        linridge.fit(standardized_X_poly_train, y_poly_train)\n",
    "        r2_train_ridge.append(linridge.score(standardized_X_poly_train, y_poly_train))\n",
    "        r2_test_ridge.append(linridge.score(standardized_X_poly_test, y_poly_test))\n",
    "    \n",
    "    best_ridgereg_r_2_train = max(r2_train_ridge)\n",
    "    index= r2_train_ridge.index(max(r2_train_ridge))\n",
    "    best_ridgereg_r_2_test = r2_test_ridge[index]\n",
    "    \n",
    "    print('R-squared score of Ridge Regression (train): {:.3f}'.format(best_ridgereg_r_2_train))\n",
    "    print('R-squared score of Ridge Regression (test): {:.3f}'.format(best_ridgereg_r_2_test))\n",
    "        \n",
    "    # -------------------- Lasso ---------------------------\n",
    "    r2_train_lasso = []\n",
    "    r2_test_lasso = []\n",
    "    for alpha in alpha_list:\n",
    "        linlasso = Lasso(alpha).fit(standardized_X_poly_train, y_poly_train)\n",
    "        r2_train_lasso.append(linlasso.score(standardized_X_poly_train, y_poly_train))\n",
    "        r2_test_lasso.append(linlasso.score(standardized_X_poly_test, y_poly_test))\n",
    "        \n",
    "    best_lassoreg_r_2_train = max(r2_train_lasso)\n",
    "    index= r2_train_lasso.index(max(r2_train_lasso))\n",
    "    best_lassoreg_r_2_test = r2_test_lasso[index]\n",
    "    \n",
    "        \n",
    "    print('R-squared score of Lasso Regression (train): {:.3f}'.format(best_lassoreg_r_2_train))\n",
    "    print('R-squared score of Lasso Regression (test): {:.3f}'.format(best_lassoreg_r_2_test))\n",
    "    \n",
    "    \n",
    "    return (linreg_r_2_train, linreg_r_2_test, best_ridgereg_r_2_train, best_ridgereg_r_2_test, \n",
    "            best_lassoreg_r_2_train, best_lassoreg_r_2_test)\n",
    "answer_five_compare()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "si670f19_lab_2_ans.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
